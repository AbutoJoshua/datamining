{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it's\", 'its', 'itself', 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she's\", 'should', \"should've\", 'shouldn', \"shouldn't\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', 'were', 'weren', \"weren't\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dictTF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-2cf6d7029a4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdictTF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m \u001b[0mdictIDF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomputeIDF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcomputeIDF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-248f057e607a>\u001b[0m in \u001b[0;36mcomputeIDF\u001b[1;34m()\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[0mdictIDF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdictTF\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m         \u001b[0mdictIDF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mdictTF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dictTF' is not defined"
     ]
    }
   ],
   "source": [
    "import os, nltk\n",
    "from nltk.tokenize import RegexpTokenizer, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "corpusroot = './presidential_debates/presidential_debates'\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokenizer = RegexpTokenizer(r'[A-Z|a-z|0-9]*')\n",
    "\n",
    "num_of_docs = 0;\n",
    "TFdictionary = {}\n",
    "\n",
    "\n",
    "print(sorted(stopwords.words('english')))\n",
    "for filename in os.listdir(corpusroot):\n",
    "    file = open(os.path.join(corpusroot, filename), \"r\", encoding='UTF-8')\n",
    "    doc = file.read()\n",
    "    num_of_docs += 1\n",
    "    file.close() \n",
    "    doc = doc.lower()\n",
    "    \n",
    "    #Tokenizing the document\n",
    "    tokens = tokenizer.tokenize(doc)\n",
    "    token_list = [s.strip(' ') for s in tokens]\n",
    "    #print(tokens)\n",
    "    #print(sorted(tokens))\n",
    "    \n",
    "    #Removing the stop words and the spaces\n",
    "    filtered_sentence = [w for w in token_list if not w in stop_words]\n",
    "    filtered_sentence = [w for w in filtered_sentence if not w in '']\n",
    "    \n",
    "    #Stemming the filtered words\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_words = []\n",
    "    for token in filtered_sentence:\n",
    "        stemmed_words.append(stemmer.stem(token))\n",
    "    #print(stemmed_words)\n",
    "    \n",
    "    #Calculating the TF for each term in each document\n",
    "    for word in stemmed_words:\n",
    "        if word in TFdictionary:\n",
    "            TFdictionary[word] += 1\n",
    "        else:\n",
    "            TFdictionary[word] = 1\n",
    "    \n",
    "def computeTF(document):\n",
    "    #Returns tf dictionary for each document, where the key is the term and the value is the corresponding tf\n",
    "    \n",
    "    #count the number of times it appears in review\n",
    "    dictTF = {}\n",
    "    for word in document:\n",
    "        if word in dictTF:\n",
    "            dictTF[word] += 1\n",
    "        else:\n",
    "            dictTF[word] = 1\n",
    "            \n",
    "    #Compute the tf for each word\n",
    "    for word in dictTF:\n",
    "        dictTF[word] = dictTF[word]/len(document)\n",
    "        \n",
    "    return dictTF\n",
    "\n",
    "dictIDF = computeIDF()\n",
    "\n",
    "def computeIDF():\n",
    "    #Returns a dictionary where the value of the keys represent the idf\n",
    "    \n",
    "    dictIDF = {}\n",
    "    \n",
    "    for word in dictTF:\n",
    "        dictIDF[word] = math.log(len(data)/dictTF[word])\n",
    "        \n",
    "    return dictIDF\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def computeTFIDF(dictTF):\n",
    "    #returns a dictionary whose values have the corresponding TF-IDF calculation\n",
    "    \n",
    "    dictTF_IDF = {}\n",
    "    \n",
    "    for word in dictTF:\n",
    "        dictTF_IDF[word] = dictTF[word] * dictIDF[word]\n",
    "    \n",
    "    return dictTF_IDF\n",
    "\n",
    "final_dictTF_IDF = [computeTFIDF(dictTF) for document in dictTF ]\n",
    "\n",
    "#constructing a vector\n",
    "wordDictionary = sorted(TFdictionary.keys())\n",
    "\n",
    "def computeTFIDFVector(document):\n",
    "    tf_idfVector = [0.0] *len(wordDictionary)\n",
    "    \n",
    "    # For each unique word, if it is in the review, store its TF-IDF value.\n",
    "    for i, word in enumerate(wordDictionary):\n",
    "          if word in review:\n",
    "            tf_idfVector[i] = document[word]\n",
    "    return tf_idfVector\n",
    "\n",
    "tfidfVector = [computeTFIDFVector(document) for review in tf_idfDict]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-41f5f0f2f2a2>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-41f5f0f2f2a2>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    for i is less than 9:\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "temp = {{}}\n",
    "j = 0\n",
    "for i less than 9:\n",
    "    temp={{j}}\n",
    "    j++\n",
    "    i++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
